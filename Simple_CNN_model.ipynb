{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure sequential model\n",
    "\n",
    "The sequential model is always built up in the following way:\n",
    "First you initialize the model as sequential with `mode=Seqential()`. Then you can add layers to the model  with `mode.add()`. \n",
    "Layers need some input parameters to work. Depending on the layer the parameter change. We will explain all parameters below and link them to the layers. \n",
    "\n",
    "\n",
    "**Structure when working with images (CNN)**\n",
    "\n",
    "The model structure starts with a first layer which has as additional information the input_size. Following layers do not need that as they orient on the first layer output. \n",
    "You can add all kinds of layers in different combination afterwards. For image classification you mainly mix `conv2D` layers with `MaxPolling` layers. For classification tasks, the last layer is often a dense layer with softmax activation and hidden_layers=number of classes. Thereby, the weight are \"ziped\" to the number of classes to classify. Before this last step, you have to flatten the data as it is still in form of the input dimensions which is e.g., 2D(grayscale), 3D(RGB), or 4D(RGBa). We want an array with a value per class. \n",
    "To increase bias and improve convergence you can drop a `dropout` layer once in a while. \n",
    "These base structures (shown below in the `Einfaches_CNN_Model` function) have been proven to work well for image classification tasks. \n",
    "\n",
    "The artist part is to combine all layers at hand in unique ways to obtain best results for the task. Known network structures such as VGG, ResNet,... can be seen as such artworks. \n",
    "\n",
    "**Structure when working with time series data (RNN)**\n",
    "\n",
    "Models for timeseries data are very similar in their construction but use different layer compositions. \n",
    "The central difference is that the main layer is not the `Conv2D` but an `LSTM` or `GRU` layer wich are specific for time series analysis. The flatten layer is also not needed as the layers give an estimation output for each timestep.\n",
    "\n",
    "**Structure when working with generative networks**\n",
    "\n",
    "we will not look into generative networks :-)\n",
    "\n",
    "\n",
    "## Main types of layer \n",
    "\n",
    "\n",
    "- Max- / sum- / mean- Pooling1D, ...2d\n",
    " \n",
    "  After the first convolution layer, the the dimensions can increase drastically. Therefore, downsampling is needed. \n",
    "  \n",
    "  The pooling layer is a form of non linear down-sampling. An image is segmented into non overlapping rectangles and returns one max, sum or, mean value for each of this rectangles. Thereby, the size is reduced by the number of rectangles. \n",
    "  The different functions represent the patterns of the subregions differently. \n",
    "\n",
    "- Dropout\n",
    "\n",
    "- Flatten\n",
    "\n",
    "- Dense\n",
    "\n",
    "\n",
    "- Conv1D (temporal sequence), Conv2D (image), Conv3D (volumen)\n",
    "\n",
    "\n",
    "\n",
    "- simpleRNN\n",
    "\n",
    "- LSTM (CuDNNLSTM when using GPU)\n",
    "\n",
    "- GRU (CuDNNGRU when using GPU)\n",
    "\n",
    "- ConvLSTM2D\n",
    "\n",
    "\n",
    "- merge\n",
    "\n",
    "- embedding \n",
    "\n",
    "- activation\n",
    "\n",
    "\n",
    "- masking\n",
    "\n",
    "- ActivityRegularization\n",
    "\n",
    "- input\n",
    "- Reshape\n",
    "- permute\n",
    "- RepeatVector\n",
    "\n",
    "\n",
    "## Parameter\n",
    "\n",
    " - hidden layers or notes or neurons\n",
    " \n",
    " \n",
    " - input_shape\n",
    "\n",
    "   If you are using a sequential model, the first layer needs to know the input dimensions of your data. The data must have same dimensions over all samples(Images). (there are exceptions, but don^t go there)\n",
    "   \n",
    "   \n",
    "\n",
    "- num_category\n",
    "\n",
    "- kernel_size\n",
    "\n",
    "- activation\n",
    "\n",
    "## Optimizers\n",
    "\n",
    "## Regularizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Einfaches_CNN_Model(input_shape,num_category):\n",
    "    #model building\n",
    "    model = Sequential()\n",
    "    #convolutional layer with rectified linear unit activation\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    #32 convolution filters used each of size 3x3\n",
    "    #again\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    #64 convolution filters used each of size 3x3\n",
    "    #choose the best features via pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #randomly turn neurons on and off to improve convergence\n",
    "    model.add(Dropout(0.25))\n",
    "    #flatten since too many dimensions, we only want a classification output\n",
    "    model.add(Flatten())\n",
    "    #fully connected to get all relevant data\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    #one more dropout for convergence' sake :) \n",
    "    model.add(Dropout(0.5))\n",
    "    #output a softmax to squash the matrix into output probabilities\n",
    "    model.add(Dense(num_category, activation='softmax'))\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure for functional API models\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
